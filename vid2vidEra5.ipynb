{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vid2vidEra5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr66J3QnaebF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vid2vid model to predict meteorological parameters based on ERA5 data\n",
        "\n",
        "# Adapted from the pix2pix models developed here: \n",
        "# (1) https://www.tensorflow.org/tutorials/generative/pix2pix\n",
        "# (2) https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5vBJQfFQUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install netCDF4\n",
        "!apt-get install libgeos-3.5.0\n",
        "!apt-get install libgeos-dev\n",
        "!pip install https://github.com/matplotlib/basemap/archive/master.zip\n",
        "!pip install pyproj==1.9.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiHNOV8koDF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "from netCDF4 import Dataset\n",
        "\n",
        "from google.colab import drive, files\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Conv3D, Conv3DTranspose, Reshape, Flatten, \\\n",
        "  LeakyReLU, Activation, Dropout, Concatenate, BatchNormalization, \\\n",
        "  ConvLSTM2D, ZeroPadding3D\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "from tensorflow.keras import metrics, losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6xRf7BkQShM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VzpsBEbQJeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eHuFTWEp76K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Which field to forecast\n",
        "field = 'geo'\n",
        "# field = 'tp'\n",
        "# field = 't2m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMP1_whS7BvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To run this, replace the path to the path of the downloaded ERA5 data (single level, pressure level, monthly means)\n",
        "# from https://climate.copernicus.eu/climate-reanalysis for the domain specified in the paper\n",
        "if field == 'geo':\n",
        "  ncfid = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5Geopotential500.nc', mode='r') \n",
        "  ncfidc = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5Climatology500.nc', mode='r') \n",
        "elif field == 'tp':\n",
        "  ncfid = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5Precipitation.nc', mode='r') \n",
        "  ncfidc = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5Climatology2m.nc', mode='r') \n",
        "elif field == 't2m':\n",
        "  ncfid = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5T2m.nc', mode='r') \n",
        "  ncfidc = Dataset('/content/gdrive/My Drive/Colab Notebooks/Era5Climatology2m.nc', mode='r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WhHI_1pLtRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if field == 'geo':\n",
        "  z = ncfid.variables['z'][:,:-1:2,:-1:2]\n",
        "  z_c = ncfidc['z'][:,:-1:2,:-1:2]\n",
        "elif field == 'tp':\n",
        "  z = ncfid.variables['tp'][:,:-1:2,:-1:2]\n",
        "  z_c = ncfidc['tp'][:,:-1:2,:-1:2]\n",
        "elif field == 't2m':\n",
        "  z = ncfid.variables['t2m'][:,:-1:2,:-1:2]\n",
        "  z_c = ncfidc['t2m'][:,:-1:2,:-1:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvdx4_wgrVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the auxiliary data\n",
        "lon = ncfid.variables['longitude'][:-1:2]\n",
        "lat = ncfid.variables['latitude'][:-1:2]\n",
        "time = ncfid.variables['time'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr4orfcuhUE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add fourth dimension to data\n",
        "z = np.expand_dims(z, axis=3)\n",
        "z_c = np.expand_dims(z_c, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OOg5J6jTOUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into train and test data (0.8 -> 4 years of training, 1 year of testing)\n",
        "test_split = int(0.8*len(z))\n",
        "\n",
        "z_train = z[:test_split,]\n",
        "z_test = z[test_split:,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG84DvnVL3WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "z_mean = z_train.mean()\n",
        "z_std = z_train.std()\n",
        "\n",
        "z_train = (z_train-z_mean)/z_std\n",
        "z_test = (z_test-z_mean)/z_std\n",
        "z_c = (z_c-z_mean)/z_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcuYKGWocC0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resize the data (to speed up training)\n",
        "z_train = tf.image.resize(z_train[:,], [128, 128], method=tf.image.ResizeMethod.BILINEAR)\n",
        "z_test = tf.image.resize(z_test[:,], [128, 128], method=tf.image.ResizeMethod.BILINEAR)\n",
        "z_c = tf.image.resize(z_c[:,], [128, 128], method=tf.image.ResizeMethod.BILINEAR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boP12PyLhAla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resize the associated lat/long data\n",
        "latInterp = interp1d(np.linspace(1, len(lat), len(lat)), lat)\n",
        "lonInterp = interp1d(np.linspace(1, len(lon), len(lon)), lon)\n",
        "\n",
        "lat = latInterp(np.linspace(1, len(lat), 128))\n",
        "lon = lonInterp(np.linspace(1, len(lon), 128))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyDq_XBIgjGL",
        "colab_type": "code",
        "outputId": "9a30f7b9-578b-4677-88e4-9292f60b87cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(z_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11686, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbe2yE52wpdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Frames to predict\n",
        "frames = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nehN1Ti2-SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data shape\n",
        "samples, m, n, _ = z_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU9TPUhZ420C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input data shape\n",
        "input_shape = (frames, m, n, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BhFxaoDqDVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the encoder block\n",
        "def define_encoder_block(layer_in, n_filters, stride, batchnorm=True):\n",
        "\t\n",
        "  # weight initialization\n",
        "\tinit = tf.random_normal_initializer(0., 0.02)\n",
        "\t\n",
        "  # add downsampling layer\n",
        "\tg = Conv3D(n_filters, (4,4,4), strides=(stride,2,2), padding='same', \n",
        "            kernel_initializer=init, use_bias=False)(layer_in)\n",
        "\t\n",
        "  # conditionally add batch normalization\n",
        "\tif batchnorm:\n",
        "\t\tg = BatchNormalization()(g, training=True)\n",
        "\t# leaky relu activation\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\treturn g\n",
        " \n",
        "# define the decoder block\n",
        "def decoder_block(layer_in, skip_in, n_filters, stride, dropout=True):\n",
        "\t\n",
        "  # weight initialization\n",
        "\tinit = tf.random_normal_initializer(0., 0.02)\n",
        "\t\n",
        "  # add upsampling layer\n",
        "\tg = Conv3DTranspose(n_filters, (4,4,4), strides=(stride,2,2), padding='same', \n",
        "                     kernel_initializer=init, use_bias=False)(layer_in)\n",
        "\t\n",
        "  # add batch normalization\n",
        "\tg = BatchNormalization()(g, training=True)\n",
        " \n",
        "\t# conditionally add dropout\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.2)(g, training=True)\n",
        "\t\n",
        "  # merge with skip connection\n",
        "\tg = Concatenate()([g, skip_in])\n",
        "\t\n",
        "  # relu activation\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esq9yRAKqPFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(image_shape):\n",
        "\t\n",
        "  # weight initialization\n",
        "\tinit = tf.random_normal_initializer(0., 0.02)\n",
        "\t\n",
        "  # image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t\n",
        "  # encoder model:\n",
        "\te1 = define_encoder_block(in_image, 64, 2, batchnorm=False)\n",
        "\te2 = define_encoder_block(e1, 128, 2)\n",
        "\te3 = define_encoder_block(e2, 256, 2)\n",
        "\te4 = define_encoder_block(e3, 256, 1)\n",
        "\te5 = define_encoder_block(e4, 256, 1)\n",
        "\tb = define_encoder_block(e5, 256, 1)\n",
        " \n",
        "\t# bottleneck LSTM \n",
        "\tb = ConvLSTM2D(256, (2,2), padding='same', return_sequences=True,\n",
        "\t               dropout=0.2, recurrent_dropout=0.2)(b, training=True)\n",
        "\tb = ConvLSTM2D(256, (2,2), padding='same', return_sequences=True,\n",
        "\t               dropout=0.2, recurrent_dropout=0.2)(b, training=True)\n",
        "\t\n",
        "  # decoder model:\n",
        "\td1 = decoder_block(b, e5, 256, 1)\n",
        "\td2 = decoder_block(d1, e4, 256, 1)\n",
        "\td3 = decoder_block(d2, e3, 256, 1, dropout=False)\n",
        "\td4 = decoder_block(d3, e2, 128, 2, dropout=False)\n",
        "\td5 = decoder_block(d4, e1, 64, 2, dropout=False)\n",
        "\t\n",
        "  # output\n",
        "\tg = Conv3DTranspose(1, (4,4,4), strides=(2,2,2), padding='same', \n",
        "                     kernel_initializer=init)(d5)\n",
        "\tout_image = Activation('linear')(g)\n",
        " \t\n",
        "  # define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YCz4eY5WWd_",
        "colab_type": "code",
        "outputId": "ad04c777-1257-4fd2-dc6e-ab60d7ce4fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define generator\n",
        "generator = define_generator(input_shape)\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8, 128, 128, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 4, 64, 64, 64 4096        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 4, 64, 64, 64 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 2, 32, 32, 12 524288      leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2, 32, 32, 12 512         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 2, 32, 32, 12 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 1, 16, 16, 25 2097152     leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1, 16, 16, 25 1024        conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 1, 16, 16, 25 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 1, 8, 8, 256) 4194304     leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1, 8, 8, 256) 1024        conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1, 8, 8, 256) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 1, 4, 4, 256) 4194304     leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 4, 4, 256) 1024        conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 1, 4, 4, 256) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 1, 2, 2, 256) 4194304     leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1, 2, 2, 256) 1024        conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 1, 2, 2, 256) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 1, 2, 2, 256) 2098176     leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)     (None, 1, 2, 2, 256) 2098176     conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose (Conv3DTranspo (None, 1, 4, 4, 256) 4194304     conv_lst_m2d_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1, 4, 4, 256) 1024        conv3d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1, 4, 4, 256) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 4, 4, 512) 0           dropout[0][0]                    \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 4, 4, 512) 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_1 (Conv3DTrans (None, 1, 8, 8, 256) 8388608     activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1, 8, 8, 256) 1024        conv3d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1, 8, 8, 256) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 8, 8, 512) 0           dropout_1[0][0]                  \n",
            "                                                                 leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1, 8, 8, 512) 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_2 (Conv3DTrans (None, 1, 16, 16, 25 8388608     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1, 16, 16, 25 1024        conv3d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 16, 16, 51 0           batch_normalization_7[0][0]      \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 16, 16, 51 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_3 (Conv3DTrans (None, 2, 32, 32, 12 4194304     activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 2, 32, 32, 12 512         conv3d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 2, 32, 32, 25 0           batch_normalization_8[0][0]      \n",
            "                                                                 leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 2, 32, 32, 25 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_4 (Conv3DTrans (None, 4, 64, 64, 64 1048576     activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 64, 64, 64 256         conv3d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4, 64, 64, 12 0           batch_normalization_9[0][0]      \n",
            "                                                                 leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4, 64, 64, 12 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_5 (Conv3DTrans (None, 8, 128, 128,  8193        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 128, 128,  0           conv3d_transpose_5[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 45,635,841\n",
            "Trainable params: 45,631,617\n",
            "Non-trainable params: 4,224\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjnJmw78U2Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_discriminator(in_shape=input_shape):\n",
        "\n",
        "  # Weight initialization\n",
        "  init = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp_X = Input(shape=in_shape) # Input layer past data\n",
        "  inp_Y = Input(shape=in_shape) # Input layer future data\n",
        "\n",
        "  # Concatenate data\n",
        "  h = Concatenate()([inp_X, inp_Y])\n",
        "\n",
        "  h = define_encoder_block(h, 64, 2, batchnorm=False)\n",
        "  h = define_encoder_block(h, 128, 1)\n",
        "  h = define_encoder_block(h, 256, 1)\n",
        "\n",
        "  h = ZeroPadding3D()(h)\n",
        "  h = Conv3D(512, (4,4,4), strides=(1,1,1),\n",
        "                                kernel_initializer=init,\n",
        "                                use_bias=False)(h)\n",
        "  h = BatchNormalization()(h)\n",
        "  h = LeakyReLU(alpha=0.2)(h)\n",
        "\n",
        "  h = ZeroPadding3D()(h)\n",
        "  h = Conv3D(1, (4,4,4), strides=(1,1,1),\n",
        "                                kernel_initializer=init)(h)\n",
        "  outp = Activation('sigmoid')(h)\n",
        "\n",
        "  model = Model([inp_X, inp_Y], outp)\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                optimizer=Adam(lr=0.0002, beta_1=0.5),\n",
        "                loss_weights=[0.5])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJxtNfl8WdZF",
        "colab_type": "code",
        "outputId": "1567f0a2-df02-490f-8ede-ee1f2294d104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "discriminator = define_discriminator(input_shape)\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 8, 128, 128, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 8, 128, 128, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 128, 128,  0           input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 4, 64, 64, 64 8192        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 4, 64, 64, 64 0           conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 4, 32, 32, 12 524288      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 4, 32, 32, 12 512         conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 4, 32, 32, 12 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 4, 16, 16, 25 2097152     leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 16, 16, 25 1024        conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 4, 16, 16, 25 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding3d (ZeroPadding3D)  (None, 6, 18, 18, 25 0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 3, 15, 15, 51 8388608     zero_padding3d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 3, 15, 15, 51 2048        conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 3, 15, 15, 51 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding3d_1 (ZeroPadding3D (None, 5, 17, 17, 51 0           leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 2, 14, 14, 1) 32769       zero_padding3d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 2, 14, 14, 1) 0           conv3d_10[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,054,593\n",
            "Trainable params: 11,052,801\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZn2EgF4zCYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now combine generator and discriminator into GAN model\n",
        "def define_gan(g_model, d_model, image_shape):\n",
        "\n",
        "\t# Discriminator is not trainable\n",
        "\td_model.trainable = False\n",
        "\n",
        "\t# Input video\n",
        "\tin_src = Input(shape=image_shape)\n",
        "\t\n",
        "\t# Generator input\n",
        "\tgen_out = g_model(in_src)\n",
        "\t\n",
        "\t# Input video and generator video are input to discriminator\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        " \n",
        "\t# GAN model\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\n",
        "\t\n",
        "\t# Compile with loss weights as in Isola et al. (2017)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1, 100])\n",
        "\t\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbO-xC-Ed0Z7",
        "colab_type": "code",
        "outputId": "9376d9fd-19fd-4094-a75a-51e6d693551d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "gan = define_gan(generator, discriminator, input_shape)\n",
        "gan.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 8, 128, 128, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model (Model)                   (None, 8, 128, 128,  45635841    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 2, 14, 14, 1) 11054593    input_4[0][0]                    \n",
            "                                                                 model[1][0]                      \n",
            "==================================================================================================\n",
            "Total params: 56,690,434\n",
            "Trainable params: 45,631,617\n",
            "Non-trainable params: 11,058,817\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ_ydQaF14wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a batch of random samples, returns images and target\n",
        "def generate_real_samples(data, frames, n_samples, patch_shape):\n",
        "\n",
        "  samples, m, n, c = data.shape\n",
        "\n",
        "  ind = np.random.randint(0, samples-2*frames, n_samples)\n",
        "  X = np.zeros((n_samples, frames, m, n, c))\n",
        "  Y = np.zeros((n_samples, frames, m, n, c))\n",
        "  \n",
        "  for i in range(0, n_samples):\n",
        "    X[i,] = data[ind[i]:ind[i]+frames,]\n",
        "    Y[i,] = data[ind[i]+frames:ind[i]+2*frames,]\n",
        "  \n",
        "  # True data so label = 1\n",
        "  y = np.ones((n_samples, 2, patch_shape, patch_shape, 1))\n",
        "\n",
        "  return [X, Y], y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKA5vwat-8fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\t\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(samples)\n",
        "\t\n",
        "\t# Fake data so label = 0\n",
        "\ty = np.zeros((len(X), 2, patch_shape, patch_shape, 1))\n",
        "\t\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRB3Mzwq_Etv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(g_model, d_model, gan_model, dataset, frames,\n",
        "          n_epochs=20, n_batch=16, n_patch=14):\n",
        "\t\n",
        "\t#E poch counter\n",
        "\tcurr_epoch = 0\n",
        "\n",
        "  # Calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t\n",
        "  # Calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t\n",
        "  # Manually enumerate epochs\n",
        "\tfor i in range(1, n_steps):\n",
        "\t\t\n",
        "\t\t# select a batch of real samples\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, frames, \n",
        "                                                     n_batch, n_patch)\n",
        "\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\n",
        "    # update discriminator for real samples\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\t\n",
        "    # update discriminator for fake samples\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\t\n",
        "    # update the generator\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\t\n",
        "    # summarize performance\n",
        "\t\tprint('>Epoch %d, Batch %d, d1[%g] d2[%g] g[%g]' % (curr_epoch, i+1, d_loss1, d_loss2, g_loss))\n",
        "\t\n",
        "\t\t# Save model at each epoch to finally pick best one (change that to model callbacks in the future)\n",
        "\t\tif i%bat_per_epo == 0:\n",
        "\t\t\tprint('Saving model at epoch {}'.format(curr_epoch))\n",
        "\t\t\tgan_model.save('gan_epoch' + str(curr_epoch) + '.h5')\n",
        "\t\t\tg_model.save('generator_epoch' + str(curr_epoch) + '.h5')\n",
        "\t\t\td_model.save('discriminator_epoch' + str(curr_epoch) + '.h5')\n",
        "\t\t\tcurr_epoch += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeRzylEZvwcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now train the GAN\n",
        "train_gan(generator, discriminator, gan, z_train, frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBlXRNblhf4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change units of data for plotting purpose\n",
        "# For precipitation: m to mm\n",
        "if field == 'geo':\n",
        "  scale = 1/9.81\n",
        "  T0 = 0\n",
        "# For geopential height: m to gpm\n",
        "elif field == 'tp':\n",
        "  scale = 1000\n",
        "  T0 = 0\n",
        "# For temperature: Kelvin to Celsius\n",
        "elif field == 't2m':\n",
        "  scale = 1\n",
        "  T0 = -273.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9kCQAdGC731",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chooses a random sample from the test data set\n",
        "def generate_sample(data, frames, input_shape):\n",
        "\n",
        "  samples, m, n, c = data.shape\n",
        "  ind = np.random.randint(frames, samples-frames, 1)\n",
        "\n",
        "  X = np.zeros((1, frames, m, n, c))\n",
        "  Y = np.zeros((1, frames, m, n, c))\n",
        "  X[0,] = data[ind[0]-frames:ind[0],]\n",
        "  Y[0,] = data[ind[0]:ind[0]+frames,]\n",
        "  \n",
        "  return ind, X, Y\n",
        "\n",
        "# Chooses a specific example by index from the test data set\n",
        "def generate_specific_sample(ind, data, frames, input_shape):\n",
        "\n",
        "  samples, m, n, c = data.shape\n",
        "\n",
        "  X = np.zeros((1, frames, m, n, c))\n",
        "  Y = np.zeros((1, frames, m, n, c))\n",
        "  X[0,] = data[ind[0]-frames:ind[0],]\n",
        "  Y[0,] = data[ind[0]:ind[0]+frames,]\n",
        "  \n",
        "  return ind, X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRduQyalbg4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting functions for individual results\n",
        "def plot_results(data, data_ref, ind, do_plot=False):\n",
        "\n",
        "  samples, frames, _, _, _ = data.shape\n",
        "  for i in range(frames):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "    plt.subplot(131)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    m.pcolormesh(lon, lat, scale*(z_std*data[0,i,:,:,0]+z_mean)+T0, \n",
        "                 latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    plt.title('vid2vid')\n",
        "\n",
        "    plt.subplot(132)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    m.pcolormesh(lon, lat, scale*(z_std*data_ref[0,i,:,:,0]+z_mean)+T0, \n",
        "                 latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    plt.title('Ground truth')\n",
        "\n",
        "    plt.subplot(133)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    if field == 'geo' or field == 't2m':\n",
        "      rr = z_std*(data[0,i,:,:,0]-data_ref[0,i,:,:,0])/(z_std*data_ref[0,i,:,:,0]+ z_mean)\n",
        "      # rr = scale*(z_std*(data[0,i,:,:,0]-data_ref[0,i,:,:,0]))\n",
        "      plt.title('Relative error')\n",
        "    elif field == 'tp':\n",
        "      rr = scale*(z_std*(data[0,i,:,:,0]-data_ref[0,i,:,:,0]))\n",
        "      plt.title('Absolute error')\n",
        "    m.pcolormesh(lon, lat, rr, latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    \n",
        "    if do_plot==True:\n",
        "      plt.savefig(\"Run\" + str(ind) + \"_frame\" + str(i) + \".png\")\n",
        "      files.download(\"Run\" + str(ind) + \"_frame\" + str(i) + \".png\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e79NJzFMTSC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting function for ensemble predictions\n",
        "def plot_ensemble(data, data_mean, data_std, ind, do_plot=False):\n",
        "\n",
        "  samples, frames, _, _, _ = data.shape\n",
        "  for i in range(frames):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "    plt.subplot(131)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    m.pcolormesh(lon, lat, scale*(z_std*data[0,i,:,:,0]+z_mean)+T0, \n",
        "                 latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    plt.title('Ground truth')\n",
        "\n",
        "    plt.subplot(132)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    m.pcolormesh(lon, lat, scale*(z_std*data_mean[0,i,:,:,0]+z_mean)+T0, \n",
        "                 latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    plt.title('Ensemble mean')\n",
        "\n",
        "    plt.subplot(133)\n",
        "    m = Basemap(projection='cyl',\n",
        "                llcrnrlon=-30,\n",
        "                llcrnrlat=30.5, \n",
        "                urcrnrlon=29.5, \n",
        "                urcrnrlat=90, resolution='l')\n",
        "    m.pcolormesh(lon, lat, scale*data_std[0,i,:,:,0], latlon=True, cmap=plt.cm.coolwarm)\n",
        "    m.colorbar(location='bottom')\n",
        "    m.drawcoastlines(color='black')\n",
        "    plt.title('Ensemble stdev')\n",
        "\n",
        "    if do_plot==True:\n",
        "      plt.savefig(\"Ensemble_run\" + str(ind) + \"_frame\" + str(i) + \".png\")\n",
        "      files.download(\"Ensemble_run\" + str(ind) + \"_frame\" + str(i) + \".png\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbdtAJCZxtva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the generator by generating a random example\n",
        "# ind, X, Y = generate_sample(z_test, frames, input_shape)\n",
        "# Y_pred = generator.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8-BLxaddyrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The proper plotting and verification routines are in the accompanying\n",
        "# vid2vidEra5_plotting_and_verification notebook. The following just serves to \n",
        "# quickly visualize some results of the trained models "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2gZU7JcDKbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate some specific examples \n",
        "# cases = 2208 (Lorenzo)\n",
        "# cases = 1290 (Hailstorms)\n",
        "ind, X, Y = generate_specific_sample(np.array([1290]), z_test, frames)\n",
        "Y_pred = generator.predict(X)\n",
        "print(datetime(2015, 1, 1, 0, 0) + +timedelta(hours=int(3*test_split)) + timedelta(hours=int(3*ind)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myy-7ddcy6q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(Y_pred, Y, ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3TCI8CRaOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runs = 100\n",
        "Y_pred = generator(X)\n",
        "Y_pred = generator.predict(X)\n",
        "Y_prob = np.stack([generator(X, training=True) \\\n",
        "                     for sample in range(runs)])\n",
        "\n",
        "Y_mean = Y_prob.mean(axis=0)\n",
        "Y_std = (z_std*Y_prob+z_mean).std(axis=0)\n",
        "\n",
        "plot_ensemble(Y, Y_mean, Y_std, ind)\n",
        "print(datetime(2019, 1, 1) + timedelta(hours=int(3*ind)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtO7NmC-AKNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick out particular locations for spaghetti ensemble\n",
        "\n",
        "cities = ['bergen','rome','tromso','kalamata','reykjavik','vienna','london',\n",
        "          'innsbruck', 'athens', 'lisbon', 'dublin','munich','milan']\n",
        "lat_cities = [60.23, 41.9028, 69.6492, 37.0366, 64.1466, 48.208, 51.5074, \n",
        "              47.2692, 37.9838, 38.7223, 53.3498, 48.1351, 45.4642]\n",
        "lon_cities = [5.195, 12.4964, 18.9553, 22.1144, -21.9426, 16.374, -0.128,\n",
        "              11.4041, 23.7275, -9.1393, -6.2603, 11.5820, 9.1900]\n",
        "\n",
        "# cities = ['innsbruck']\n",
        "# lat_cities = [47.2692]\n",
        "# lon_cities = [11.4041]\n",
        "\n",
        "# Loop over cities to make ensemble plots\n",
        "for i in range(len(cities)):\n",
        "  lat_point = lat_cities[i]\n",
        "  lon_point = lon_cities[i]\n",
        "  city = cities[i]\n",
        "\n",
        "  # Find associated values in prediction (here we pick the closest point to the city,\n",
        "  # rather than interpolating to the city to avoid introducing an additional interpolation error)\n",
        "  i_lat = np.abs(lat-lat_point) == np.min(np.abs(lat-lat_point))\n",
        "  i_lon = np.abs(lon-lon_point) == np.min(np.abs(lon-lon_point))\n",
        "\n",
        "  z_point_true = z_std*Y[0,:, i_lat, i_lon, 0].flatten()+z_mean\n",
        "  z_point_mean = z_std*Y_mean[0,:, i_lat, i_lon, 0].flatten()+z_mean\n",
        "  z_point_std = Y_std[0,:, i_lat, i_lon, 0].flatten()\n",
        "\n",
        "  # Plot enembles\n",
        "  plt.plot(np.linspace(3,3*frames,frames), scale*z_point_true+T0)\n",
        "  plt.plot(np.linspace(3,3*frames,frames), scale*z_point_mean+T0,'k')\n",
        "  for i in range(100):\n",
        "    z_curr =  z_std*Y_prob[i,0,:, i_lat, i_lon, 0].flatten() + z_mean+T0\n",
        "    #plt.plot(np.linspace(3,3*frames,frames), scale*z_curr, 'k', lw=0.1)\n",
        "  plt.fill_between(np.linspace(3,3*frames,frames), \n",
        "                   scale*(z_point_mean-10*z_point_std)+T0, \n",
        "                   scale*(z_point_mean+10*z_point_std)+T0,\n",
        "                   facecolor='k', alpha=0.5)\n",
        "  plt.legend(['ERA5','ML_mean','ML_ens'])\n",
        "  plt.grid()\n",
        "  plt.xlim([3,3*frames])\n",
        "  plt.xticks(ticks=np.linspace(3,3*frames,frames))\n",
        "  plt.xlabel('Forecast time [h]')\n",
        "\n",
        "  if field == 'geo':\n",
        "    plt.ylabel('z [m]')\n",
        "    plt.savefig('z_ensemble_' + city + '.png')\n",
        "    files.download('z_ensemble_' + city + '.png')\n",
        "  elif field == 'tp':\n",
        "    plt.ylabel('tp [mm]')\n",
        "    plt.savefig('tp_ensemble_' + city + '.png')\n",
        "    files.download('tp_ensemble_' + city + '.png')\n",
        "  elif field == 't2m':\n",
        "    plt.ylabel('t2m [°C]')\n",
        "    plt.savefig('t2m_ensemble_' + city + '.png')\n",
        "    files.download('t2m_ensemble_' + city + '.png')\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81tPiTcSafEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the models (to be used in plotting and verification routine)\n",
        "generator.save('generator.h5')\n",
        "discriminator.save('discriminator.h5')\n",
        "gan.save('gan.h5')\n",
        "files.download('generator.h5')\n",
        "files.download('discriminator.h5')\n",
        "files.download('gan.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}